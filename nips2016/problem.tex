\section{Problem statement}
\label{sec:assumptions}

Before stating our assumptions formally, we give a concrete example that our 
assumptions are meant to capture. 
We suppose that there is an unobserved matrix $\Aavg \in [0,1]^{n \times m}$
of ratings, such that $\Aavg_{ij}$ denotes the rating that person $i$ would 
assign (in expectation) to item $j$. 
We also let $\rtrue \in [0,1]^m$ denote the unobserved vector 
specifying our own ratings. Rather than observing $\Aavg$ and $\rtrue$, 
we observe noisy, scaled-up versions $\Aobs$ and $\robs$:
\[ \Aobs_{ij} = \left\{ \begin{array}{ccl} \frac{n}{k}\Aavg_{ij} & : & \text{ with probability $\frac{k}{n}$} \\ 0 & : & \text{ else} \end{array} \right., \quad\quad 
  \robs_j = \left\{ \begin{array}{ccl} \frac{n}{k_0}\rtrue_j & : & \text{ with probability $\frac{k_0}{n}$} \\ 0 & : & \text{ else} \end{array} \right.. \] %}}
Note that the scaling ensures that $\bE[\Aobs] = \Aavg$ and $\bE[\robs] = \rtrue$. 

For a vector $v \in \bR^m$, let $Q_{\beta}(v)$ denote the \emph{$\beta$-quantile} 
of $v$ --- that is, the $\beta m$ coordinates $j$ for which $v_j$ is largest.
We assume that there is a set $\good \subseteq [n]$ of good raters such 
that $Q_{\beta}(\Aavg_{i}) = Q_{\beta}(\rtrue)$ for all $i \in \good$, and our 
goal is to recover $\beta$-quantile of $\rtrue$. More precisely, we wish to 
recover a set $T$ of size $\beta m$ such that
\[ \frac{1}{\beta m}\p{\sum_{j \in T} \rtrue_j - \sum_{j \in Q_{\beta}(\rtrue)} \rtrue_j} \geq - \epsilon. \]

\paragraph{General Setting}
The example above is limited in a few ways; first, it makes a very specific 
assumption about the randomness in $\Aobs$ and $\robs$. Second, it implicitly 
assumes that the adversaries' actions are chosen independently of which items 
they are assigned to rate, which is implausible. Finally, it assumes that 
$\bE[\Aobs_i] = \rtrue$ for all $i \in \good$, which among other things rules out 
having noisy raters with different levels of noise for each rater.


For a matrix $X$, 
we will let $X_{\good}$ denote the rows of $X$ indexed by $\good$, 
and $X_{\bad}$ the remaining rows. We assume that $\good$ is a constant 
fraction of $[n]$: $|\good| \geq \goodfrac n$ for some $\goodfrac$.
The important properties of $\Aobs$ are summarized below. In the following, 
$\Aavg$ is a matrix that is often the expected value of $\Aobs$, while 
$\fac$ is a constant that will turn out to be proportional to the number 
of observed ratings in each row.


% assumptions:
% set of good users C
% ``expected ratings'' A_{\sC}
%   - all share same \beta-quartile
%   - all assign average score at least 1/2 to it
% ``actual ratings'' \A_{\sC}
%   - \|A_{\sC} - \A_{\sC}\|_op \leq n / sqrt(fac)
%   - \Au_{\bad}
First, we assume that the $\beta$-quantile of $\Aobs$ is correct 
``in expectation'':
\begin{assumption}[Shared Quantiles]
\label{ass:quantile}
There exists a matrix $\Aavg_{\good} \in [0,1]^{\good \times m}$ such that 
$Q_{\beta}(\Aavg_i) = Q_{\beta}(\rtrue)$. Moreover, 
$\|\Aobs_{\good} - \Aavg_{\good}\|_{\op} \leq \frac{m}{\sqrt{\fac}}\max\p{1, \sqrt{n/m}}$.
\end{assumption}
In most settings, standard matrix concentration bounds will imply that 
$\fac$ is proportional to the number of entries of $\Aobs$ that are observed 
in each row. It seems possible to relax Assumption~\ref{ass:quantile} to only 
require approximate match of the $\beta$-quantiles, but that is beyond the 
scope of this paper.\footnote{For instance, we believe that 
a sufficient condition is that the union of the $\beta$-quantiles of the good 
users has size at most $\beta m \cdot \p{1 + 1/\sqrt{|\good|}}$.}

Next, we assume that our rating is a Lipschitz function of the average 
honest rating:
\begin{assumption}[Lipschitz ratings]
\label{ass:lipschitz}
There exists a constant $L$ such that 
\[ \rtrue_j - \rtrue_{j'} \leq \frac{L}{|\good|}\sum_{i \in \good} \Aavg_{ij} - \Aavg_{ij'} \]
for all $j \in Q_{\beta}(r^*), j' \not\in Q_{\beta}(r^*)$.
\end{assumption}
Assumption~\ref{ass:lipschitz} is important because it implies that 
near-optimal solutions with respesct to the $\Aavg_i$ are also near-optimal 
with respect to $\rtrue$.
To avoid excessive notation, we will assume that $L = \oo\p{1}$ throughout 
the paper (say, $L \leq 3$). To recover the dependence on $L$, simply replace 
all instances of the error $\error$ in the results below with $\error/L$.

Our final assumption bounds the impact of the adversaries:
\begin{assumption}[Bounded Adversaries]
\label{ass:adversary}
There exists a matrix $\Aavg_{\bad} \in [-\infty,1]^{\bad \times m}$ such that 
$\|\Aobs_{\bad} - \Aavg_{\bad}\|_{\op} \leq \frac{m}{\sqrt{\fac}}\max\p{1, \sqrt{n/m}}$.
\end{assumption}

As before, the condition 
$\|\Aobs_{\bad} - \Aavg_{\bad}\|_{\op} \leq \frac{m}{\sqrt{\fac}}$ is what 
we would typically get out of matrix concentration bounds.
However, some care is needed because the adversary's strategy can depend on 
the randomness in $\Aobs$, and it is therefore not obvious that such concentration 
bounds should apply. What saves us is that $\Aavg_{\bad}$ need not correspond to 
any sort of expected value, and the only constraint it need satisfy is that 
$\max_{i \in \bad, j \in [m]} \Aavg_{ij} \leq 1$. 
As a result, the worst the adversary can do is make $\Aobs_{ij}$ is as 
large as possible; for instance, in the example from the beginning of 
the section, $\Aobs_{ij} = \frac{m}{k}\bI[(i,j) \in \Obs]$ for all $i \in \bad$.
Since $\Aobs$ now only depends on the structure of $\Obs$, standard concentration 
bounds once again hold.

Assumptions~\ref{ass:quantile}, \ref{ass:lipschitz}, and \ref{ass:adversary} 
all hold for the running example when $k = \Theta(\fac)$:
\begin{proposition}
Suppose that $\Aobs_{ij} = \frac{m}{k}E_{ij}\Anom_{ij}$, 
where the $E_{ij}$ i.i.d. $\operatorname{Bernoulli}(\frac{k}{m})$, and 
$\Anom_{ij}$ is the rating that person $i$ assigns to item $j$. Further 
assume that for each $i \in \good$, $\bE[\Anom_{i}] = \Aavg_i$, 
for $\Aavg_i$ satisfying Assumptions~\ref{ass:quantile} and \ref{ass:lipschitz},
 and that the $\Anom_{ij}$ are jointly independent for 
$i \in \good$, $j \in [m]$. (The $\Anom_{ij}$ for $i \in \bad$ can be 
arbitrarily dependent on each other, as well as on $E$ and on 
$\Anom_{\good}$.)

%
%Suppose that the following scheme is carried out: 
%for each $i,j \in [n] \times [m]$, with probability $\frac{k}{m}$ person 
%$i$ is asked to supply a rating for item $j$ that lies in $[-1,1]$. 
%Then $\Aobs_{ij}$ is set to be the rating scaled by $\frac{m}{k}$, or else 
%$0$ if we did not ask for a rating. When choosing a response, the 
%users reply with rating whose expectation is $\Aavg_{ij}$, where 
%$\Aavg_i$ satisfies Assumption~\ref{ass:A}. The dishonest users reply 
%with an output that may depend on the ratings of the honest users, the 
%randomness in the procedure, and the ratings of the other dishonest users.

Then, assuming that $k \geq \fac + \sqrt{\fac \log(1/\delta)}$, 
Assumption~\ref{ass:norm} holds with probability $1-\delta$, where $\Aavg_i$ is 
as defined above for $i \in \good$, and 
$\Aavg_{ij} = 1 + \frac{m}{k}E_{ij}(\Anom_{ij} - 1)$ for $i \in \bad$.
\end{proposition}


\begin{assumption}
\label{ass:r}
The observed rating vector $\rtrue$ satisfies \todo{include condition}
\end{assumption}
