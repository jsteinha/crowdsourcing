\section{Bounding the Effect of Adversaries (Proposition~\ref{prop:subgradient})}
\label{sec:subgradient-proof}
In this section we prove Proposition~\ref{prop:subgradient}.
Let $\sP_0$ be the superset of $\sP$ where we have removed the 
nuclear norm constraint. By Lagrangian duality we 
know that there is some $\mu$ such that maximizing 
$\langle \Aa, M \rangle$ over $\sP \cap \{M_{\sC} = R_{\sC}\}$ 
is equivalent to maximizing $f_\mu(M) \eqdef \langle \Aa, M \rangle + \mu\p{\frac{2}{\epsilon\alpha}\sqrt{\frac{\alpha n}{\beta m}} - \|M\|_*}$ over 
$\sP_0 \cap \{M_{\sC} = R_{\sC}\}$. 

We start by bounding $\mu$. We claim that $\mu \leq \epsilon \sqrt{\alpha\beta nm}$. 
To show this, first note that for any $M \in \sP_0$, we have 
\begin{align}
\langle \Aa, M \rangle &\leq \langle \Aavg, M \rangle + \langle \Aa - \Aavg, M \rangle \\
 &\leq n + \|\Aa - \Aavg\|_{\op}\|M\|_* \\
 &\leq n + \frac{m}{\sqrt{\fac}}\|M\|_* \\
 &\leq n + \frac{\epsilon\sqrt{\alpha\beta nm}}{2}\|M\|_*,
\end{align}
where in the last step we used the assumption $\fac = \Omega\p{\frac{1}{\alpha\beta\epsilon^2}\frac{m}{n}}$.

Now, suppose that we take $\mu_0 = \epsilon \sqrt{\alpha\beta nm}$ and optimize $\langle \Aa, M \rangle - \mu_0\|M\|_*$ over 
$\sP_0 \cap \{M_{\sC} = R_{\sC}\}$. Since $\langle \Aa, M \rangle - \mu_0\|M\|_* \leq n - \frac{\epsilon \sqrt{\alpha\beta nm}}{2}\|M\|_*$, 
any $M$ with $\|M\|_* > \frac{2}{\epsilon\alpha}\sqrt{\frac{\alpha n}{\beta m}}$ cannot possibly be optimal, since the solution $M = 0$ would 
be better. Hence, $\mu_0$ is a large enough Lagrange multiplier to ensure that $M \in \sP$, and so 
$\mu \leq \mu_0 = \epsilon \sqrt{\alpha\beta nm}$, as claimed.

We next characterize the subgradient of $f_{\mu}$ at $M = \Mm$.
Define the projection matrix $P$ as
\[ P_{i,i'} = \left\{ \begin{array}{ccl} \frac{1}{|\sC|} & : & i, i' \in \sC \\ \delta_{i,i'} & : \text{else} \end{array} \right.. \]
Thus $PM = M$ if and only if all rows in $\sC$ are equal to each other.
In particular, $PM = M$ whenever $M_{\sC} = R_{\sC}$. Now, since $\Mm$ is the maximum 
of $f_{\mu}(M)$ over all $M \in \sP_0 \cap \{M_{\sC} = R_{\sC}\}$, there must be some 
$B \in \partial f(\Mm)$ such that $\langle B, M - \Mm \rangle \leq 0$ for all $M \in \sP_0 \cap \{M_{\sC} = R_{\sC}\}$.
\begin{lemma}
\label{lem:subgradient}
Suppose that $B \in \partial f(\Mm)$ satisfies $\langle B, M - \Mm \rangle \leq 0$ for all $M \in \sP_0 \cap \{M_{\sC} = R_{\sC}\}$. 
Then, $PB$ satisfies the same property, and lies in $\partial f(\Mm)$ as well.
\end{lemma}
We can further note (by differentiating $f_{\mu}$) that 
$B = \Aa - \mu Z_0$, where $\|Z_0\|_{\op} \leq 1$. Hence 
$PB = P\Aa - \mu PZ_0 = \Aa - \mu PZ_0$. Let $r(M)$ denote the 
matrix where $M_{\sC}$ is replaced with $R_{\sC}$ (so $r(M) \in \sP_0 \cap \{R_{\sC} = M_{\sC}\}$ 
whenever $M \in \sP_0$). The rest of the proof is basically algebra:
\begin{align}
\langle \Aa, M - \Mm \rangle &\stackrel{(i)}{\leq} f_{\mu}(M) - f_{\mu}(\Mm) \\
 &\stackrel{(ii)}{\leq} \langle \Aa - \mu PZ_0, M - \Mm \rangle \\
 &= \langle \Aa - \mu PZ_0, M - r(M) \rangle + \langle \Aa - \mu PZ_0, r(M) - \Mm \rangle \\
 &\stackrel{(iii)}{\leq} \langle \Aa - \mu PZ_0, M - r(M) \rangle \\
 &= \langle \Aa_{\sC} - \mu (PZ_0)_{\sC}, M_{\sC} - r(M)_{\sC} \rangle \\
 &= \langle \Aa_{\sC} - \mu (PZ_0)_{\sC}, M_{\sC} - \Mm_{\sC} \rangle,
\end{align}
where (i) is by complementary slackness (either $\mu = 0$ or $\|\Mm\|_* = \frac{2}{\alpha\epsilon}$); 
(ii) is concavity of $f_{\mu}$, and the fact that $\Aa - \mu PZ_0$ is a subgradient; and 
(iii) is the property from Lemma~\ref{lem:subgradient} ($\langle \Aa - \mu PZ_0, r(M) - \Mm \rangle \leq 0$ since 
$r(M) \in \sP_0$).

To finish, we will take $Z = \mu (PZ_0)_{\sC}$. We note that
$\|Z\|_{\op} = \|\mu (PZ)_{\sC}\|_{\op} \leq \mu \|PZ\|_{\op} \leq \mu \|Z\|_{\op} \leq \mu$.
Moreover, $Z$ has rank $1$ and so $\|Z\|_F = \|Z\|_{\op} \leq \mu \leq \epsilon\sqrt{\alpha\beta nm}$, as was to be shown.

