\section{Assumptions and Approach}
\label{sec:assumptions}
\label{sec:approach}

We now state our assumptions more formally, state the general form 
of our results, and outline the key ingredients of the proof.
Recall that we obtain a matrix $\A \in [0,1]^{n \times m}$ by asking each 
rater $i \in [n]$ to rate each item $j \in [m]$ with probability $\frac{k}{m}$ 
(while avoiding giving any rater too many items to rate, as in Algorithm~\ref{alg:recover-M}).
Let $\Obs$ be the set of ratings $(i,j)$ that are observed, and let $\good \subset [n]$ 
be the set of reliable raters, where $|\good| \geq \alpha n$.
Our main assumption is that the reliable raters make independent errors; we also 
need a way of measuring agreement between our ratings and those of the reliable 
raters.
% the amount of agreement will show up in our final error bounds --- if 
%there is no agreement then the error will be high. 
We formalize both the 
independence assumption and the notion of agreement below.

\begin{assumption}[Independence]
\label{ass:independent}
The values $\A_{i,j}$ for $i \in \good$, $j \in [m]$, are 
jointly independent.
In addition, the values $\robs_j$ are jointly independent 
of each other as well as of $\A$ (including $\A_i$ for $i \not \in \good$).
\end{assumption}
Note that Assumption~\ref{ass:independent} allows the unreliable ratings to 
depend on the reliable ratings, allows arbitrary collusion among the unreliable 
raters, and even allows the unreliable raters to know the pattern of random 
assignments of the ratings. The only restriction on the unreliable raters is 
that they may not depend on \emph{our} randomness (i.e., the randomness in 
$\robs$). This can be ensured, for instance, if we wait to generate our 
personal randomness until after everyone else has submitted their ratings. 
%(assuming the adversaries don't gain access to our pseudorandom seed). 
% JS: I cut this because it didn't seem important in the current formulation
%We are also implicitly assuming that the adversaries cannot influence the set of 
%items in a way that causes us or the reliable raters to accidentally rate a bad 
%item highly or vice versa.

We next need a way of formalizing the idea that the reliable raters should 
agree with us. To this end, we let 
$\Aavg_{i,j} \eqdef \bE[\A_{i,j} \mid (i,j) \in \Obs]$ and $\ravg_j$ denote the expected 
rating that we assign to item $j$ (we assume $\ravg$ is the true rating we want to maximize).
We want $\Aavg$ to be approximately increasing in $\ravg$:
\begin{definition}[Monotonic raters]
\label{def:lipschitz}
We say that the reliable raters are \emph{$(L,\epsilon)$-monotonic} if their 
average ratings satisfy
\begin{equation}
\label{eq:lipschitz}
\ravg_j - \ravg_{j'} \leq L \cdot (\Aavg_{i,j} - \Aavg_{i,j'}) + \epsilon
\end{equation}
whenever $\ravg_j \geq \ravg_{j'}$, and
for all $i \in \good$ and all $j,j' \in [m]$.
\end{definition}
The $(L,\epsilon)$-monotonicity property says that if we think that one item is 
substantially better than another item, the reliable raters should think 
so as well. As an example, suppose that our own ratings are binary 
($\ravg_j \in [0,1]$) and that each rating $\Aobs_{i,j}$ matches $\ravg_j$ 
with probability $\frac{3}{5}$. Then 
$\Aavg_{i,j} = \frac{2}{5} + \frac{1}{5}\ravg_j$, 
and hence the ratings are $(5,0)$-monotonic. 
In general, the monotonicity property is fairly mild --- if the reliable ratings 
are not $(L,\epsilon)$-monotonic, it is not clear that they should 
even be called reliable!

With Assumption~\ref{ass:independent} and Definition~\ref{def:lipschitz} 
in place, we are ready to state our main result. 

\todo{include $\delta$ dependence for $k$ once we get the 
right matrix concentration bound}
\begin{theorem}
\label{thm:main}
Suppose Assumption~\ref{ass:independent} holds, and that each rater is 
assigned to rate $k$ items at random, that we rate $k'$ items at random, 
where $k \geq \Omega\p{\frac{1}{\beta\alpha^3\epsilon^4}\max\p{1, \frac{m}{n}}}$ 
and $k' \geq \Omega\p{\frac{\log(1/\alpha\beta\epsilon\delta)}{\beta\epsilon^2}}$.
Then, if the reliable raters are $(L,\epsilon_0)$-monotonic, running 
Algorithms~\ref{alg:recover-M} and \ref{alg:recover-T} recovers a set 
$T$ satisfying 
\[ \frac{1}{\beta m} \p{\sum_{j \in T^*} \ravg_j - \sum_{j \in T} \ravg_j} 
\leq (L+1) \cdot \epsilon + \epsilon_0 \]
with probability $1-\delta$, where $T^*$ is the $\beta$-quantile of $\ravg$.
\end{theorem}

The proof of Theorem~\ref{thm:main} can be split into two parts: analyzing 
Algorithm~\ref{alg:recover-M} (Section~\ref{sec:approach-M}), 
and analyzing Algorithm~\ref{alg:recover-T} (Section~\ref{sec:approach-T}). 
At a high level, analyzing Algorithm~\ref{alg:recover-M} involves showing that 
the nuclear norm constraint in \eqref{eq:optimization-noisy} imparts sufficient 
noise robustness while not allowing the adversary too much influence over the 
reliable rows of $\M$. Analyzing~\ref{alg:recover-T} is far more straightforward, 
and requires only standard concentration inequalities and a standard randomized 
rounding idea (though the latter is perhaps not well-known, so we will explain 
it briefly in Section~\ref{sec:approach-T}).

