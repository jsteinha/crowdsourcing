\section{Introduction}
\label{sec:intro}

Consider the following hypothetical scenario: it is the night before the 
NIPS deadline, and you are a professor with an army of $n$ graduate students, 
each of whom has written a paper.  Some fraction, $\goodraters$, of these 
students are ``highly competent''---namely, they both produce good papers, as 
well as accurately review papers (i.e. determine whether a given paper is good 
or not).  The remaining $1-\goodraters$ fraction of your graduate students 
behave arbitrarily---some of them might still produce great papers, and some 
might still give accurate reviews.  Of course, as the professor, you are also 
capable of accurately reviewing papers.  You want to choose a large subset of 
the students' papers to submit to NIPS, at least $\goodraters n$, and you want 
to ensure that most of the submitted papers are good.  The question is how to 
choose this subset while minimizing the amount of work you do (i.e. the number 
of papers you review), as well as minimizing the number of papers you assign 
each student to review. Unfortunately, you yourself have forgotten which students 
in your lab are competent, so part of the task is to determine this.
%
Perhaps surprisingly, we show that even with an arbitrarily large number of 
students, $n$, and even if the non-competent students are all colluding to 
get their papers submitted, you can successfully accomplish this task while 
performing only a constant amount of work yourself (dependent on the fraction 
of ``highly competent'' students), and having each student only do a constant 
amount of work!

We can model this problem more precisely (as well as more generally) as follows: 
we assume that there are $m$ items and $n$ raters. We define a matrix 
$\Anom \in \{0,1\}^{n \times m}$ where $\Anom_{ij}$ denotes the rating that 
rater $i$ assigns to item $j$ ($1$ if good and $0$ if bad); in the setting above, 
the raters are graduate students and the items are papers. 
The value $\Anom_{ij}$ is observed only if rater $i$ rates item $j$. 
Similarly, we let the vector $\rtrue \in \{0,1\}^n$ denote 
our own ratings of items, which we assume are accurate; as before, 
$\rtrue_{j}$ is observed only if we rate item $j$.

We make the following assumptions:
\begin{enumerate}
\item There is a set $\good$ of honest raters of size at least $\goodfrac n$, 
      such that $\Anom_i$ agrees stochastically with $\rtrue$ in the sense that 
      $\bP[\Anom_{ij} = \rtrue_j] \geq \frac{2}{3}$ for all $i \in \sC$ and 
      $j \in [m]$, and furthermore the $\Anom_{ij}$ are independent.
\item For the dishonest raters, $\Anom_{ij}$ can be chosen adversarially, 
      with full knowledge of which ratings everyone was assigned and how the 
      honest users behaved, and in collusion with all of the other 
      dishonest raters.
\end{enumerate}
Assuming that there are at least $\beta m$ good items, our goal is to obtain 
a set $T \subseteq [m]$ of size $\beta m$, such that 
$\frac{1}{\beta m} \sum_{j \in T} \rtrue_j \geq 1-\epsilon$.
The reults of this paper imply that we can do this with minimal work per rater:
\begin{theorem}
\label{thm:main-1}
Suppose that each rater is assigned $k$ items to rate at random, and that we rate 
$k_0$ items at random. Then, assuming that $k \geq \Omega\p{\frac{1}{\alpha^3\beta\epsilon^4} + \frac{\log(1/\delta)}{\alpha\beta\epsilon^2}}$, and 
$k_0 \geq \Omega\p{\frac{\log(1/\alpha\delta)}{\alpha\beta\epsilon^2}}$, 
with probability $1-\delta$ we can recover a set $T$ of size $\gooditems m$, 
such that $\frac{1}{\gooditems m} \sum_{j \in T} \rtrue_j \geq 1-\epsilon$.
\end{theorem}
The main computational step in the recovery algorithm involves solving a 
nuclear-norm constrained optimization problem (where all of the remaining 
constraints are linear inequalities). \todo{talk about runtime?}

Beyond the professorial scenario above, the above setup
models the challenge of crowdsourcing the creation of a large 
dataset. While several mechanisms have been proposed for ensuring high-quality 
data in crowdsourcing applications, most assume that there are ``gold labels'' 
that can be used to assess worker performance during the course of 
data collection; moreover, most mechanisms make assumptions about the behavior 
of workers (e.g. that workers that behaved well before will continue to 
behave well, or that they act to maximize a certain payoff function).
In this work we are motivated by cases where there is not necessarily a single 
correct answer --- for instance, tasks such as ``draw an interesting picture'' 
or ``translate this sentence'', where different workers could generate different 
equally good answers. In this case, the only way to evaluate quality is 
via evaluation by other workers or by the manager of the experiment. 
Moreover, since workers will often try to game the system (in order to 
get paid), we would like to model non-cooperative workers as adversarial. 
More generally, our setup can be appropriate in any quality 
control setting where the workers responsible for assessing reliability 
may themselves be unreliable. \todo{should we talk about twitter?}

While we have stated a very concrete setup for simplicity, our results 
hold in a substantially more general setting that we call \textbf{quantile 
estimation}. The ratings are now allowed to lie in $[0,1]$, and 
our goal is to recover the \emph{$\beta$-quantile} $Q_{\beta}$ of 
$\rtrue$, defined as the $\beta m$ indices $j$ for which $\rtrue_j$ is largest. 
In order to do this, we need to make $3$ assumptions, which are relaxations of 
the assumptions above: (1) the $\beta$-quantile of each of the honest raters 
matches the $\beta$-quantile of $\rtrue$; (2) the ratings in $\rtrue$ are a 
Lipschitz function of the average rating 
$\frac{1}{|\good|}\sum_{i \in \good} \Anom_i$; and (3) the ratings assigned by 
the honest raters are sufficiently independent for typical matrix 
concentration bounds to hold. We formalize these assumptions in 
Section~\ref{sec:assumptions}. \todo{talk about stochastic block model}

The rest of the paper is organized as follows. In Section~\ref{sec:assumptions}, 
we state our formal assumptions and main results, and show some concrete 
settings in which they apply. In Section~\ref{sec:approach}, we outline a proof 
of our main results and present a concrete algorithm for $\beta$-quantile 
estimation, deferring the more technical proofs until later. 
In Section~\ref{sec:subgradient-proof}, we provide the proof of 
Proposition~\ref{prop:subgradient}, which is the key result bounding the effect 
that the adversaries can have on the solution quality. We end in 
Section~\ref{sec:discussion} with a discussion.
